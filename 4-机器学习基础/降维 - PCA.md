# 降维 - PCA

---







---

## QA

### 1. PCA  中第一主成分是第一的原因？

<https://www.nowcoder.com/questionTerminal/7e9febebe3d3467ca5ea17e013d416f0>

### 2. 讲一下 PCA

PCA是比较常见的线性降维方法，通过线性投影将高维数据映射到低维数据中。 所期望的是在投影的维度上，新特征自身的方差尽量大，方差越大特征越有效，尽量使产生的新特征间的相关性越小。

PCA算法的具体操作为**对所有的样本进行中心化操作**，计算样本的协方差矩阵，然后对协方差矩阵做特征值分解，取最大的n个特征值对应的特征向量构造投影矩阵。





> ### 2.15.4 PCA算法流程总结
>
> 输入：$n$ 维样本集 $D = \left( x^{(1)},x^{(2)},...,x^{(m)} \right)$ ，目标降维的维数 $n'$ 。
>
> 输出：降维后的新样本集 $D'  = \left( z^{(1)},z^{(2)},...,z^{(m)} \right)$ 。
>
> 主要步骤如下：
>
> 1. 对所有的样本进行中心化，$ x^{(i)} = x^{(i)} - \frac{1}{m} \sum^m_{j=1} x^{(j)} $ 。
> 2. 计算样本的协方差矩阵 $XX^T$ 。
> 3. 对协方差矩阵 $XX^T$ 进行特征值分解。
> 4. 取出最大的 $n' $ 个特征值对应的特征向量 $\{ w_1,w_2,...,w_{n'} \}$ 。
> 5. 标准化特征向量，得到特征向量矩阵 $W$ 。
> 6. 转化样本集中的每个样本 $z^{(i)} = W^T x^{(i)}$ 。
> 7. 得到输出矩阵 $D' = \left( z^{(1)},z^{(2)},...,z^{(n)} \right)$ 。
>    *注*：在降维时，有时不明确目标维数，而是指定降维到的主成分比重阈值 $k(k \epsilon(0,1])$ 。假设 $n$ 个特征值为 $\lambda_1 \geqslant \lambda_2 \geqslant ... \geqslant \lambda_n$ ，则 $n'$ 可从 $\sum^{n'}_{i=1} \lambda_i \geqslant k \times \sum^n_{i=1} \lambda_i $ 得到。